# Machine Learning Lab 03

##  Overview
This project is a **demonstration of how to prepare data, train, evaluate, and visualize decision boundaries for different supervised learning algorithms** using the **Iris dataset** and the **Moons dataset**.  
It follows exercises from *Python Machine Learning, Chapter 3*.


##  Features
- **Data Preparation**: Train/test split, stratification, standardization.
- **Perceptron**: Simple linear classifier.
- **Logistic Regression**: Multi-class classification.
- **Support Vector Machines (SVM)**: Linear and Kernel (RBF).
- **Decision Trees**: Controlled depth, Gini impurity.
- **Random Forests**: Ensemble learning with feature importance.
- **K-Nearest Neighbors (KNN)**: Distance-based classification.
- **Hyperparameter Tuning**: GridSearchCV for SVM optimization.
- **Decision Region Visualization**: Helper function to plot classifier boundaries.
- **Model Comparison**: Accuracy scores across all classifiers.


##  Technologies Used
- **Python **
- **NumPy**
- **Matplotlib**
- **Scikit-learn**


## ðŸ›  Installation & Usage

### 1. Clone the repository

git clone https://github.com/Mkhenso-jay/Machine_Learning_LAB03.git
cd Machine_Learning_LAB03

## 2.Run the script
python fulllab03.py

## Results

Visualizations of decision boundaries for different classifiers.

Accuracy comparison of Perceptron, Logistic Regression, SVM, Decision Tree, Random Forest, and KNN.

Hyperparameter tuning results for Kernel SVM.

## Learning Outcomes

Understand how different classifiers work and their strengths.

Learn preprocessing and standardization techniques.

Practice visualization of decision regions.

Gain experience with hyperparameter tuning and model evaluation.
